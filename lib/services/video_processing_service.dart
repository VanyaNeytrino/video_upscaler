import 'dart:io';
import 'dart:async';
import 'dart:math';
import 'dart:convert';
import 'package:path/path.dart' as path;
import 'package:video_upscaler/models/processing_config.dart';
import 'package:video_upscaler/services/executable_manager.dart';
import 'package:video_upscaler/services/system_info_service.dart';
import 'package:video_upscaler/services/resource_monitor.dart';

class VideoProcessingService {
  final StreamController<String> _progressController =
      StreamController<String>.broadcast();
  final StreamController<double> _percentageController =
      StreamController<double>.broadcast();

  Stream<String> get progressStream => _progressController.stream;
  Stream<double> get percentageStream => _percentageController.stream;

  bool _isProcessing = false;
  String? _tempBasePath;

  bool get isProcessing => _isProcessing;

  Future<String> processVideo(ProcessingConfig config) async {
    if (_isProcessing) {
      throw Exception('–£–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ');
    }

    _isProcessing = true;

    try {
      _updateProgress('–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ExecutableManager...', 0.0);
      final executableManager = ExecutableManager.instance;

      if (!await executableManager.validateInstallation()) {
        throw Exception(
            'ExecutableManager –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏–ª–∏ —Ñ–∞–π–ª—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.');
      }

      _updateProgress('–ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...', 5.0);
      final systemInfo = await SystemInfoService.analyzeSystem();

      // –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ö–æ–¥–Ω–æ–º –≤–∏–¥–µ–æ
      final videoInfo = await _analyzeInputVideo(config.inputVideoPath);

      // –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥ –∂–µ–ª–µ–∑–æ –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
      final optimizedParams =
          await _getOptimizedParameters(systemInfo, videoInfo, config);

      print('=== –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ ===');
      print('–°–∏—Å—Ç–µ–º–∞: ${systemInfo.systemSummary}');
      print(
          '–í—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ: ${videoInfo['width']}x${videoInfo['height']} @ ${videoInfo['fps']}fps');
      print(
          '–í—ã—Ö–æ–¥–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ: ${optimizedParams['output_width']}x${optimizedParams['output_height']}');
      print('–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: $optimizedParams');

      _updateProgress('–°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π...', 10.0);
      final tempDir = await _createTempDirectories();

      _updateProgress('–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –∏–∑ –≤–∏–¥–µ–æ...', 15.0);
      await _extractFrames(
          config.inputVideoPath, tempDir['frames']!, optimizedParams);

      // –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∞–¥—Ä—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
      final frameFiles = await Directory(tempDir['frames']!)
          .list()
          .where((f) => f.path.endsWith('.png'))
          .toList();
      final totalFrames = frameFiles.length;

      print('üì∏ –í—Å–µ–≥–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: $totalFrames');

      _updateProgress('–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫–∏...', 25.0);
      final hasAudio =
          await _extractAudio(config.inputVideoPath, tempDir['audio']!);

      _updateProgress('AI –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥ –∫–∞–¥—Ä–æ–≤...', 30.0);

      // –û–±–Ω–æ–≤–ª—è–µ–º ResourceMonitor —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–∞–¥—Ä–∞—Ö
      ResourceMonitor.instance.updateProgress(
        processedFrames: 0,
        totalFrames: totalFrames,
        currentStage: 'AI –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥ –∫–∞–¥—Ä–æ–≤...',
      );

      await _upscaleFramesWithProgress(
        tempDir['frames']!,
        tempDir['scaled']!,
        config,
        systemInfo,
        optimizedParams,
        totalFrames,
      );

      _updateProgress('–°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ...', 85.0);

      ResourceMonitor.instance.updateProgress(
        processedFrames: totalFrames,
        totalFrames: totalFrames,
        currentStage: '–°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ...',
      );

      final outputPath = await _assembleVideo(
        tempDir['scaled']!,
        tempDir['audio']!,
        config,
        hasAudio,
        optimizedParams,
      );

      _updateProgress('–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...', 95.0);
      await _cleanupTempFiles();

      _updateProgress('–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!', 100.0);

      ResourceMonitor.instance.updateProgress(
        processedFrames: totalFrames,
        totalFrames: totalFrames,
        currentStage: '–ó–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!',
      );

      return outputPath;
    } catch (e) {
      _updateProgress('–û—à–∏–±–∫–∞: $e', 0.0);
      await _cleanupTempFiles();

      ResourceMonitor.instance.updateProgress(
        processedFrames: 0,
        totalFrames: 0,
        currentStage: '–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏',
      );

      rethrow;
    } finally {
      _isProcessing = false;
    }
  }

  Future<Map<String, dynamic>> _analyzeInputVideo(String videoPath) async {
    final executableManager = ExecutableManager.instance;
    final ffmpegPath = executableManager.ffmpegPath;

    print('üé¨ –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ: $videoPath');

    final result = await Process.run(
      ffmpegPath,
      ['-i', videoPath, '-hide_banner'],
      runInShell: Platform.isWindows,
    );

    final output = result.stderr.toString();
    print('üìπ FFmpeg –≤—ã–≤–æ–¥: $output');

    // –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ
    final RegExp resolutionRegex = RegExp(r'(\d{2,})x(\d{2,})');
    final RegExp fpsRegex = RegExp(r'(\d+(?:\.\d+)?)\s*fps');
    final RegExp bitrateRegex = RegExp(r'(\d+)\s*kb/s');

    final resolutionMatch = resolutionRegex.firstMatch(output);
    final fpsMatch = fpsRegex.firstMatch(output);
    final bitrateMatch = bitrateRegex.firstMatch(output);

    final width =
        resolutionMatch != null ? int.parse(resolutionMatch.group(1)!) : 1920;
    final height =
        resolutionMatch != null ? int.parse(resolutionMatch.group(2)!) : 1080;
    final fps = fpsMatch != null ? double.parse(fpsMatch.group(1)!) : 30.0;
    final bitrate =
        bitrateMatch != null ? int.parse(bitrateMatch.group(1)!) : 5000;

    print(
        'üìê –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ: ${width}x${height} @ ${fps}fps, –±–∏—Ç—Ä–µ–π—Ç: ${bitrate}kb/s');

    return {
      'width': width,
      'height': height,
      'fps': fps,
      'bitrate': bitrate,
      'raw_info': output,
    };
  }

  Future<Map<String, dynamic>> _getOptimizedParameters(
    SystemCapabilities systemInfo,
    Map<String, dynamic> videoInfo,
    ProcessingConfig config,
  ) async {
    final inputWidth = videoInfo['width'] as int;
    final inputHeight = videoInfo['height'] as int;
    final inputFPS = videoInfo['fps'] as double;
    final scaleFactor = config.scaleFactor;

    final outputWidth = inputWidth * scaleFactor;
    final outputHeight = inputHeight * scaleFactor;
    final totalPixels = outputWidth * outputHeight;

    // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã waifu2x –Ω–∞ –æ—Å–Ω–æ–≤–µ –∂–µ–ª–µ–∑–∞
    Map<String, dynamic> waifu2xParams =
        _getWaifu2xParameters(systemInfo, scaleFactor);

    // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã FFmpeg –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏ –∂–µ–ª–µ–∑–∞
    Map<String, dynamic> ffmpegParams = _getFFmpegParameters(
      systemInfo,
      inputWidth,
      inputHeight,
      outputWidth,
      outputHeight,
      inputFPS,
      scaleFactor,
    );

    return {
      'output_width': outputWidth,
      'output_height': outputHeight,
      'total_pixels': totalPixels,
      'waifu2x': waifu2xParams,
      'ffmpeg': ffmpegParams,
    };
  }

  Map<String, dynamic> _getWaifu2xParameters(
      SystemCapabilities systemInfo, int scaleFactor) {
    final memoryGB = systemInfo.totalMemoryGB;
    final cpuCores = systemInfo.cpuCores;
    final platform = systemInfo.platform;

    // –ò—Å–ø—Ä–∞–≤–ª—è–µ–º scale factor - —Ç–æ–ª—å–∫–æ 1, 2, 4 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è!
    int validScaleFactor = scaleFactor;
    if (![1, 2, 4].contains(validScaleFactor)) {
      if (validScaleFactor == 3) {
        validScaleFactor = 2;
        print('‚ö†Ô∏è –ú–∞—Å—à—Ç–∞–± 3x –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º 2x');
      } else if (validScaleFactor > 4) {
        validScaleFactor = 4;
        print('‚ö†Ô∏è –ú–∞—Å—à—Ç–∞–± –±–æ–ª—å—à–µ 4x –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º 4x');
      } else {
        validScaleFactor = 2;
        print('‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –º–∞—Å—à—Ç–∞–±, –∏—Å–ø–æ–ª—å–∑—É–µ–º 2x');
      }
    }

    int tileSize = 0; // auto –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    int threads = (cpuCores / 2).round().clamp(1, 4);
    int gpuDevice = 0;

    // –ü–ª–∞—Ç—Ñ–æ—Ä–º–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    if (platform == 'macos') {
      gpuDevice = 0;
      if (validScaleFactor >= 4) {
        tileSize = 32;
      } else if (validScaleFactor >= 2) {
        tileSize = 64;
      } else {
        tileSize = 0;
      }
      print(
          'üçé Apple Silicon: GPU=0, tileSize=$tileSize –¥–ª—è ${validScaleFactor}x');
    } else if (platform == 'windows' || platform == 'linux') {
      if (systemInfo.supportsGPU && systemInfo.availableGPUs.isNotEmpty) {
        gpuDevice = 0;
        if (memoryGB >= 16) {
          tileSize = validScaleFactor >= 4 ? 200 : 400;
        } else if (memoryGB >= 8) {
          tileSize = validScaleFactor >= 4 ? 100 : 200;
        } else {
          tileSize = 100;
        }
      } else {
        gpuDevice = -1;
        tileSize = validScaleFactor >= 4 ? 50 : 100;
        threads = cpuCores.clamp(1, 8);
      }
    }

    return {
      'tile_size': tileSize,
      'threads': threads,
      'gpu_device': gpuDevice,
      'use_gpu': gpuDevice >= 0,
      'valid_scale_factor': validScaleFactor,
    };
  }

  Map<String, dynamic> _getFFmpegParameters(
    SystemCapabilities systemInfo,
    int inputWidth,
    int inputHeight,
    int outputWidth,
    int outputHeight,
    double inputFPS,
    int scaleFactor,
  ) {
    final totalPixels = outputWidth * outputHeight;
    final memoryGB = systemInfo.totalMemoryGB;

    String videoCodec = 'libx264';
    String preset = 'medium';
    int crf = 23;
    String pixFormat = 'yuv420p';

    if (totalPixels >= 3840 * 2160) {
      videoCodec = 'libx265';
      crf = 18;
      preset = memoryGB >= 16 ? 'slow' : 'medium';
      pixFormat = 'yuv420p10le';
    } else if (totalPixels >= 2560 * 1440) {
      videoCodec = 'libx264';
      crf = 20;
      preset = memoryGB >= 8 ? 'slow' : 'medium';
    } else {
      crf = 23;
      preset = 'medium';
    }

    final bitrate = _calculateOptimalBitrate(
        outputWidth, outputHeight, inputFPS, scaleFactor);
    final maxrate = (bitrate * 1.5).round();
    final bufsize = maxrate * 2;

    return {
      'video_codec': videoCodec,
      'preset': preset,
      'crf': crf,
      'pix_format': pixFormat,
      'bitrate': '${bitrate}k',
      'maxrate': '${maxrate}k',
      'bufsize': '${bufsize}k',
      'fps': inputFPS.round(),
    };
  }

  int _calculateOptimalBitrate(
      int width, int height, double fps, int scaleFactor) {
    final totalPixels = width * height;
    final pixelsPerSecond = totalPixels * fps;

    double bitsPerPixel;
    if (totalPixels >= 3840 * 2160) {
      bitsPerPixel = 0.15;
    } else if (totalPixels >= 2560 * 1440) {
      bitsPerPixel = 0.12;
    } else if (totalPixels >= 1920 * 1080) {
      bitsPerPixel = 0.10;
    } else {
      bitsPerPixel = 0.08;
    }

    if (scaleFactor >= 4) {
      bitsPerPixel *= 1.5;
    } else if (scaleFactor >= 2) {
      bitsPerPixel *= 1.2;
    }

    final bitrateKbps = (pixelsPerSecond * bitsPerPixel / 1000).round();
    return bitrateKbps.clamp(1000, 50000);
  }

  Future<Map<String, String>> _createTempDirectories() async {
    final tempBase = await Directory.systemTemp.createTemp('video_upscaler_');
    _tempBasePath = tempBase.path;

    final directories = {
      'frames': path.join(tempBase.path, 'frames'),
      'scaled': path.join(tempBase.path, 'scaled'),
      'audio': path.join(tempBase.path, 'audio.mp3'),
    };

    for (final entry in directories.entries) {
      if (!entry.key.contains('audio')) {
        await Directory(entry.value).create(recursive: true);
      }
    }

    print('–í—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–æ–∑–¥–∞–Ω—ã –≤: ${tempBase.path}');
    return directories;
  }

  Future<void> _extractFrames(
      String videoPath, String framesDir, Map<String, dynamic> params) async {
    final executableManager = ExecutableManager.instance;
    final ffmpegPath = executableManager.ffmpegPath;
    final ffmpegParams = params['ffmpeg'] as Map<String, dynamic>;

    print('–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤: $videoPath -> $framesDir');

    final args = [
      '-i',
      videoPath,
      '-vf',
      'fps=${ffmpegParams['fps']}',
      path.join(framesDir, 'frame_%06d.png'),
      '-hide_banner',
      '-loglevel',
      'error',
    ];

    final result =
        await Process.run(ffmpegPath, args, runInShell: Platform.isWindows);

    if (result.exitCode != 0) {
      throw Exception('–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤: ${result.stderr}');
    }

    final framesList = await Directory(framesDir).list().toList();
    print('–ò–∑–≤–ª–µ—á–µ–Ω–æ –∫–∞–¥—Ä–æ–≤: ${framesList.length}');
  }

  Future<bool> _extractAudio(String videoPath, String audioPath) async {
    final executableManager = ExecutableManager.instance;
    final ffmpegPath = executableManager.ffmpegPath;

    print('–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ: $videoPath -> $audioPath');

    final result = await Process.run(
      ffmpegPath,
      [
        '-i',
        videoPath,
        '-vn',
        '-acodec',
        'copy',
        audioPath,
        '-hide_banner',
        '-loglevel',
        'error',
      ],
      runInShell: Platform.isWindows,
    );

    final audioFile = File(audioPath);
    final hasAudio = await audioFile.exists() && await audioFile.length() > 0;

    if (!hasAudio) {
      print('–í–∏–¥–µ–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É –∏–ª–∏ –∞—É–¥–∏–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å');
    } else {
      print('–ê—É–¥–∏–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ');
    }

    return hasAudio;
  }

  // –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –º–µ—Ç–æ–¥ upscale —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
  Future<void> _upscaleFramesWithProgress(
    String framesDir,
    String scaledDir,
    ProcessingConfig config,
    SystemCapabilities systemInfo,
    Map<String, dynamic> optimizedParams,
    int totalFrames,
  ) async {
    final executableManager = ExecutableManager.instance;
    final waifu2xPath = executableManager.waifu2xPath;
    final waifu2xParams = optimizedParams['waifu2x'] as Map<String, dynamic>;

    print('üéØ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞');
    print('‚öôÔ∏è –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: ${systemInfo.platform}');

    if (!await File(waifu2xPath).exists()) {
      throw Exception('waifu2x-ncnn-vulkan –Ω–µ –Ω–∞–π–¥–µ–Ω: $waifu2xPath');
    }

    // –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    int validScaleFactor = waifu2xParams['valid_scale_factor'];
    int validNoise = 0; // –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

    // –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
    final modelPath =
        executableManager.getModelPath(config.modelType ?? 'cunet');

    print(
        'üîí –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: scale=${validScaleFactor}x, noise=$validNoise');
    print('üìÅ –ú–æ–¥–µ–ª—å: $modelPath');

    // –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –∞—Ä–≥—É–º–µ–Ω—Ç—ã waifu2x
    final args = [
      '-i', framesDir,
      '-o', scaledDir,
      '-n', validNoise.toString(),
      '-s', validScaleFactor.toString(),
      '-m', modelPath,
      '-g', waifu2xParams['gpu_device'].toString(),
      '-t', waifu2xParams['tile_size'].toString(),
      '-j', '1:${waifu2xParams['threads']}:1', // load:proc:save
      '-f', 'png',
      '-v',
    ];

    print('üöÄ –ö–æ–º–∞–Ω–¥–∞ waifu2x: ${args.join(' ')}');

    // –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å
    final process =
        await Process.start(waifu2xPath, args, runInShell: Platform.isWindows);

    // –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    Timer? progressTimer = Timer.periodic(Duration(seconds: 1), (timer) async {
      try {
        final processedFiles = await Directory(scaledDir)
            .list()
            .where((f) => f.path.endsWith('.png'))
            .length;

        final progressPercent =
            (processedFiles / totalFrames * 55).clamp(0, 55);

        _updateProgress(
          'AI –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥: $processedFiles/$totalFrames –∫–∞–¥—Ä–æ–≤...',
          30.0 + progressPercent,
        );

        // –û–±–Ω–æ–≤–ª—è–µ–º ResourceMonitor
        ResourceMonitor.instance.updateProgress(
          processedFrames: processedFiles,
          totalFrames: totalFrames,
          currentStage: 'AI –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥ –∫–∞–¥—Ä–æ–≤...',
          currentFile: processedFiles > 0
              ? 'frame_${processedFiles.toString().padLeft(6, '0')}.png'
              : null,
        );

        if (processedFiles >= totalFrames) {
          timer.cancel();
        }
      } catch (e) {
        // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–æ–¥—Å—á–µ—Ç–∞
      }
    });

    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—ã–≤–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–∞
    String errorOutput = '';

    process.stdout.transform(SystemEncoding().decoder).listen((data) {
      print('üì§ waifu2x stdout: $data');
    });

    process.stderr.transform(SystemEncoding().decoder).listen((data) {
      errorOutput += data;
      // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è find_blob_index_by_name
      if (!data.contains('find_blob_index_by_name')) {
        print('üì• waifu2x stderr: $data');
      }
    });

    // –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞
    final exitCode = await process.exitCode;
    progressTimer?.cancel();

    print('‚ö° waifu2x –∑–∞–≤–µ—Ä—à–µ–Ω —Å –∫–æ–¥–æ–º: $exitCode');

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    final processedFiles = await Directory(scaledDir)
        .list()
        .where((f) => f.path.endsWith('.png'))
        .length;

    print('üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: $processedFiles/$totalFrames –∫–∞–¥—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ');

    if (processedFiles < totalFrames * 0.8) {
      throw Exception(
          '–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –∫–∞–¥—Ä–æ–≤: $processedFiles/$totalFrames');
    }

    // –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    ResourceMonitor.instance.updateProgress(
      processedFrames: processedFiles,
      totalFrames: totalFrames,
      currentStage: 'AI –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω',
    );

    print('‚úÖ –ê–ø—Å–∫–µ–π–ª–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω');
  }

  Future<String> _assembleVideo(
    String scaledDir,
    String audioPath,
    ProcessingConfig config,
    bool hasAudio,
    Map<String, dynamic> optimizedParams,
  ) async {
    final executableManager = ExecutableManager.instance;
    final ffmpegPath = executableManager.ffmpegPath;
    final ffmpegParams = optimizedParams['ffmpeg'] as Map<String, dynamic>;

    print('üé¨ –°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ');

    final outputPath = config.outputPath;
    final framePattern = path.join(scaledDir, 'frame_%06d.png');

    List<String> args = [
      '-framerate',
      ffmpegParams['fps'].toString(),
      '-i',
      framePattern,
    ];

    if (hasAudio) {
      args.addAll(['-i', audioPath]);
    }

    args.addAll([
      '-c:v',
      ffmpegParams['video_codec'],
      '-preset',
      ffmpegParams['preset'],
      '-crf',
      ffmpegParams['crf'].toString(),
      '-pix_fmt',
      ffmpegParams['pix_format'],
    ]);

    if (hasAudio) {
      args.addAll(['-c:a', 'aac', '-shortest']);
    }

    args.addAll([
      '-y',
      outputPath,
      '-hide_banner',
    ]);

    print('üöÄ –ö–æ–º–∞–Ω–¥–∞ —Å–±–æ—Ä–∫–∏: ${args.join(' ')}');

    final result =
        await Process.run(ffmpegPath, args, runInShell: Platform.isWindows);

    if (result.exitCode != 0) {
      throw Exception('–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∫–∏ –≤–∏–¥–µ–æ: ${result.stderr}');
    }

    final outputFile = File(outputPath);
    if (!await outputFile.exists()) {
      throw Exception('–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω: $outputPath');
    }

    final outputSize = await outputFile.length();
    print(
        '‚úÖ –í–∏–¥–µ–æ —Å–æ–±—Ä–∞–Ω–æ: ${(outputSize / 1024 / 1024).toStringAsFixed(1)} MB');

    return outputPath;
  }

  // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ
  Future<Map<String, dynamic>> getVideoInfo(String videoPath) async {
    return await _analyzeInputVideo(videoPath);
  }

  void stopProcessing() {
    _isProcessing = false;
    _updateProgress('–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º', 0.0);
  }

  void _updateProgress(String message, double percentage) {
    _progressController.add(message);
    _percentageController.add(percentage);
  }

  Future<void> _cleanupTempFiles() async {
    if (_tempBasePath != null) {
      try {
        final tempDir = Directory(_tempBasePath!);
        if (await tempDir.exists()) {
          await tempDir.delete(recursive: true);
          print('üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã: $_tempBasePath');
        }
      } catch (e) {
        print('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: $e');
      }
      _tempBasePath = null;
    }
  }

  void dispose() {
    _progressController.close();
    _percentageController.close();
  }
}
